{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from glob import glob\n",
    "from lmfit import Model\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.sandbox.regression.predstd import wls_prediction_std\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def values_between(x, y, minimum=float, maximum=float):\n",
    "    '''\n",
    "    Finds values betwwen minimum and maximum\n",
    "       \n",
    "    \n",
    "    Parameters:\n",
    "    -------\n",
    "    x: np.array \n",
    "        X-values\n",
    "    y: np.array\n",
    "        Y.values\n",
    "    minimum: float\n",
    "        Minimum value\n",
    "    maximum: float\n",
    "        Maximum value\n",
    "        \n",
    "    Returns:\n",
    "    -------\n",
    "    x: np.array \n",
    "        X-values in the respective X-range\n",
    "    y: np.array\n",
    "        Y.values \n",
    "    \n",
    "    '''\n",
    "    y=y[(x<maximum)]\n",
    "    x=x[(x<maximum)]\n",
    "    y=y[x>minimum]\n",
    "    x=x[x>minimum]\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gauss_func(x, max_intensity, two_theta, fwhm):\n",
    "    '''\n",
    "    Represents a Gauss function\n",
    "       \n",
    "    \n",
    "    Parameters:\n",
    "    -------\n",
    "    x: np.array \n",
    "        X-values\n",
    "    max_intensity: np.array\n",
    "        Y.values\n",
    "    two_theta:\n",
    "        Two theta angle\n",
    "    fwhm:\n",
    "        Full with at half maximum\n",
    "        \n",
    "    Returns:\n",
    "    -------\n",
    "    Gauss Function\n",
    "    '''\n",
    "    return max_intensity * np.exp(-np.log(2) * ((x - two_theta) / (fwhm / 2)) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lorentz_func(x, max_intensity, two_theta, fwhm):\n",
    "    '''\n",
    "    Represents a Lorentz function\n",
    "       \n",
    "    \n",
    "    Parameters:\n",
    "    -------\n",
    "    x: np.array \n",
    "        X-values\n",
    "    max_intensity: np.array\n",
    "        Y.values\n",
    "    two_theta:\n",
    "        Two theta angle\n",
    "    fwhm:\n",
    "        Full with at half maximum\n",
    "        \n",
    "    Returns:\n",
    "    -------\n",
    "    Lorentz Function\n",
    "    '''\n",
    "    return max_intensity / (1 + ((x - two_theta) / (fwhm / 2)) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def psv_func(x, max_intensity, two_theta, fwhm, nu):\n",
    "    '''\n",
    "    Represents a Pseudo-Voigt function\n",
    "       \n",
    "    \n",
    "    Parameters:\n",
    "    -------\n",
    "    x: np.array \n",
    "        X-values\n",
    "    max_intensity: np.array\n",
    "        Y.values\n",
    "    two_theta:\n",
    "        Two theta angle\n",
    "    fwhm:\n",
    "        Full with at half maximum\n",
    "    nu: float between 0 & 1\n",
    "        nu = 1 Pure Gauss\n",
    "        nu = 0 Pure Lorentz\n",
    "        \n",
    "    Returns:\n",
    "    -------\n",
    "    PSV Function\n",
    "    '''\n",
    "    return nu * gauss_func(x, max_intensity, two_theta, fwhm) + (1 - nu) * lorentz_func(x, max_intensity, two_theta,fwhm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_psv_func(x, max_intensity_1, max_intensity_2, two_theta_1, two_theta_2, fwhm_1, fwhm_2, nu_1, nu_2, delta):\n",
    "    '''\n",
    "    Represents a Double PSV function\n",
    "       \n",
    "    \n",
    "    Parameters:\n",
    "    -------\n",
    "    x: np.array \n",
    "        X-values\n",
    "    max_intensity: np.array\n",
    "        Y.values\n",
    "    two_theta:\n",
    "        Two theta angle\n",
    "    fwhm:\n",
    "        Full with at half maximum\n",
    "    nu: float between 0 & 1\n",
    "        nu = 1 Pure Gauss\n",
    "        nu = 0 Pure Lorentz\n",
    "        \n",
    "    Returns:\n",
    "    -------\n",
    "    Double PSV Function\n",
    "    '''\n",
    "    return psv_func(x, max_intensity=max_intensity_1, two_theta=two_theta_1, fwhm=fwhm_1, nu=nu_1) + \\\n",
    "           psv_func(x, max_intensity=max_intensity_2, two_theta=two_theta_2, fwhm=fwhm_2, nu=nu_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PSVModel(Model):\n",
    "    '''\n",
    "    Implementation of the Pseudo Voigt Model\n",
    "    Super of lmfit.Model --> https://lmfit.github.io/lmfit-py/model.html#lmfit.model.Model\n",
    "    '''\n",
    "    # overload lmfit.Model constructor with specific psv-function constructor\n",
    "    def __init__(self):\n",
    "        super(PSVModel, self).__init__(psv_func, missing='drop')\n",
    "        self.name = 'pseudo-Voigt'\n",
    "\n",
    "    # implement the guessing method for start parameters\n",
    "    def guess(self, data=None, **kws):\n",
    "        # set x to range of indices, if not provided\n",
    "        assert 'x' in kws\n",
    "        x = kws['x']\n",
    "\n",
    "        # set sensible values for parameters\n",
    "        max_intensity = max(data)\n",
    "        two_theta = x[data.idxmax()]\n",
    "        try:\n",
    "            fwhm = x[data > max_intensity / 2].ptp()  # ptp = max - min\n",
    "        except:\n",
    "            fwhm = 0.1\n",
    "\n",
    "        # set physically sensible boundaries for the parameters\n",
    "        self.set_param_hint('nu', min=0, max=1)\n",
    "        self.set_param_hint('max_intensity', min=0)\n",
    "        self.set_param_hint('two_theta', min=min(x), max=max(x))\n",
    "        self.set_param_hint('fwhm', min=0)\n",
    "\n",
    "        # construct and return lmfit.Parameters object\n",
    "        pars = self.make_params(max_intensity=max_intensity, two_theta=two_theta, fwhm=fwhm, nu=0.5)\n",
    "        return pars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class  Time_Object(object):\n",
    "    '''\n",
    "    Creates a time Object with hours, minutes, seconds and milliseconds\n",
    "    '''\n",
    "    def __init__(self, hour=0, minute=0, second=0, millisecond=0):\n",
    "        self.day=0\n",
    "        self.hour = hour\n",
    "        self.minute = minute\n",
    "        self.second = second\n",
    "        self.millisecond = millisecond       \n",
    "        \n",
    "    def add_millisecond(self, milli_second):\n",
    "        '''\n",
    "        Adds a millisecond\n",
    "        '''\n",
    "        self.millisecond += milli_second\n",
    "        self.millisecond, diff = self.check(self.millisecond)\n",
    "        if diff != 0:\n",
    "            self.add_second(diff)\n",
    "            \n",
    "    def add_second(self, second):\n",
    "        '''\n",
    "        Adds a second\n",
    "        '''\n",
    "        self.second += second\n",
    "        self.second, diff = self.check(self.second)\n",
    "        if diff != 0:\n",
    "            self.add_minute(diff)\n",
    "    \n",
    "    def add_minute(self, minute):\n",
    "        '''\n",
    "        Adds a minute\n",
    "        '''\n",
    "        self.minute += minute\n",
    "        self.minute, diff = self.check(self.minute)\n",
    "        if diff != 0:\n",
    "            self.add_hour(diff)\n",
    "        \n",
    "    def add_hour(self, hour):\n",
    "        '''\n",
    "        Adds an hour\n",
    "        '''\n",
    "        self.hour += hour\n",
    "        self.hour, diff = self.check(self.hour, 24)\n",
    "        self.day += diff\n",
    "        \n",
    "    def add_day(self, day):\n",
    "        self.day += day\n",
    "        \n",
    "    def check(self, period, number_per_period=60):\n",
    "        '''\n",
    "        Checks parameters if they are in boundaries\n",
    "        '''\n",
    "        diff = int(period/number_per_period)\n",
    "        period -= diff * number_per_period\n",
    "        return period, diff\n",
    "    \n",
    "            \n",
    "    def show_time(self):\n",
    "        '''\n",
    "        Prints the time in a nice format\n",
    "        '''\n",
    "        print(f\"Day:{self.day},Hour:{self.hour}, Minute:{self.minute}, Second:{self.second}, Millisecond:{self.millisecond}\")  \n",
    "        \n",
    "    def greater_than(self, other):\n",
    "        '''\n",
    "        Compares times\n",
    "        True if self > other.\n",
    "        '''\n",
    "        if self.day > other.day:\n",
    "            return True\n",
    "        elif self.hour > other.hour:\n",
    "            return True\n",
    "        elif self.minute > other.minute:\n",
    "            return True\n",
    "        elif self.second > other.second:\n",
    "            return True\n",
    "        elif self.millisecond > other.millisecond:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "    def smaller_than(self, other):\n",
    "        '''\n",
    "        Compares times\n",
    "        True if self < other.\n",
    "        '''\n",
    "        if self.day < other.day:\n",
    "            return True\n",
    "        elif self.hour < other.hour:\n",
    "            return True\n",
    "        elif self.minute < other.minute:\n",
    "            return True\n",
    "        elif self.second < other.second:\n",
    "            return True\n",
    "        elif self.millisecond < other.millisecond:\n",
    "            return True\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(x, y, background_lower, peak, background_upper):\n",
    "    '''\n",
    "    Fits peaks  \n",
    "    \n",
    "    Parameters:\n",
    "    -------\n",
    "    x: np.array of floats\n",
    "        e.g. theta2theta data\n",
    "    y: : np.array of floats\n",
    "        e.g. intensity\n",
    "    background_lower: np.array of floats\n",
    "        indices of background before peak\n",
    "    peak: \n",
    "        indices of peak data\n",
    "    background_upper:\n",
    "        indices of background after peak\n",
    "        \n",
    "    Returns:\n",
    "    -------\n",
    "\n",
    "    '''\n",
    "    # find backgroud and fit a line\n",
    "    x_bg = np.concatenate((x[background_lower], x[background_upper]))\n",
    "    y_bg = np.concatenate((y[background_lower], y[background_upper]))\n",
    "    m, c = np.polyfit(x_bg, y_bg, 1) # fits a line according to background\n",
    "    # find peak data\n",
    "    xs = x[peak]\n",
    "    ys = y[peak]\n",
    "    # correct ys data\n",
    "    y_corr = ys - (m * xs + c)\n",
    "    \n",
    "    # create model\n",
    "    model = PSVModel()\n",
    "    \n",
    "    pars = model.guess(y_corr, x=xs) #produce start values x given as keyword argument, elsewise just range of indixes\n",
    "    fit = model.fit(y_corr, pars, x=xs) # fit model\n",
    "    #extract data from model\n",
    "    two_theta = (fit.params['two_theta'].value, fit.params['two_theta'].stderr)\n",
    "    max_intensity = (fit.params['max_intensity'].value, fit.params['max_intensity'].stderr)\n",
    "    nu = (fit.params['nu'].value, fit.params['nu'].stderr)\n",
    "    fwhm = (fit.params['fwhm'].value, fit.params['fwhm'].stderr)\n",
    "    return (two_theta, max_intensity, nu, fwhm, m, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_peak(tth, intensity, background_lower, peak_lower, peak_upper, background_upper, plot=True):\n",
    "    '''\n",
    "    Fits peaks, corrects for Background and Plots respective Data\n",
    "    \n",
    "    Parameters:\n",
    "    -------\n",
    "    tth: np.array of floats\n",
    "        Theta2Theta values\n",
    "    intensity: np.array of floats\n",
    "        Intensity at Theta2Theta values\n",
    "    background_lower: float\n",
    "        Theta2Theta value of the bottom limit of the background substraction\n",
    "    peak_lower: float\n",
    "        Theta2Theta start value of the peak\n",
    "    peak_upper: float\n",
    "        Theta2Theta end value of the peak\n",
    "    background_upper: float\n",
    "        Theta2Theta value of the upper limit of the background substraction\n",
    "        \n",
    "    Returns:\n",
    "    -------\n",
    "    two_theta: float \n",
    "        two_theta value of the peak position of the fitted peak\n",
    "    max_intensity: float\n",
    "        maximal intensity of the fitted peak\n",
    "    nu: float\n",
    "       Shapefactor of pseudo voigt profile\n",
    "    fwhm: float\n",
    "        full width at half maximum of the fitted peak\n",
    "    integral_int: float\n",
    "        integral_intensity of the fitted peak\n",
    "    integral_width: float\n",
    "        integral_width of the fitted peak\n",
    "    '''\n",
    "    # find indices of lower and upper background between the limits\n",
    "    ### Breaking changes in np.argwhere with pandas series --> np. arrays needed\n",
    "    background_lower = np.intersect1d(np.argwhere(np.array(tth) > background_lower),np.argwhere(np.array(tth) < peak_lower))\n",
    "    background_upper = np.intersect1d(np.argwhere(np.array(tth) > peak_upper),np.argwhere(np.array(tth) < background_upper))\n",
    "    # find indices between peak_lower and peak upper\n",
    "    peak = np.intersect1d(np.argwhere(np.array(tth) > peak_lower),np.argwhere(np.array(tth) < peak_upper))\n",
    "    # fit data\n",
    "    two_theta, max_intensity, nu, fwhm, m, c =  fit(tth, intensity, background_lower, peak, background_upper)\n",
    "    print(two_theta)\n",
    "    if plot:\n",
    "        plt.plot(tth[background_lower], intensity[background_lower], 'ro')\n",
    "        plt.plot(tth[background_upper], intensity[background_upper], 'ro')\n",
    "        plt.plot(tth[peak], intensity[peak], 'bo')\n",
    "        x_fit = tth[peak]\n",
    "        y_fit =  psv_func(x_fit, max_intensity[0], two_theta[0], fwhm[0], nu[0])\n",
    "        y_fit_linear = y_fit + m*x_fit + c\n",
    "        plt.plot(x_fit, y_fit, 'g--')\n",
    "        plt.plot(x_fit, y_fit_linear, 'g-')\n",
    "        plt.xlabel(\"Theta2Theata\")\n",
    "        plt.ylabel(\"Intensity\")\n",
    "        plt.show()\n",
    "    return two_theta, max_intensity, nu, fwhm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dat_file(path, file):\n",
    "    '''\n",
    "    Reads Bessy II dat data of KMCII.\n",
    "    \n",
    "    Parameters:\n",
    "    -------\n",
    "    path: String\n",
    "        Path to file\n",
    "    file: String\n",
    "        Filename including suffix .dat\n",
    "    Returns:\n",
    "    -------\n",
    "    table.TTh: pandas series \n",
    "        Theta two Theta values\n",
    "    table.Int: pandas series\n",
    "        Intensity values\n",
    "    '''\n",
    "    table = pd.read_table(f\"{path}\\\\{file}\", skiprows=15,  delimiter=\" \t\", names=[\"TTh\", \"Int\", \"N_pix\", \"Err\"], engine='python')\n",
    "    return table.TTh, table.Int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_scan_data(path, file, pattern):\n",
    "    '''\n",
    "    Extracts data from the SPEC file provided by KMCII.\n",
    "    \n",
    "    \n",
    "     Parameters:\n",
    "    -------\n",
    "    path: String\n",
    "        Path to file\n",
    "    file: String\n",
    "        Filename including suffix .dat\n",
    "    pattern: String\n",
    "        Regex to match\n",
    "        \n",
    "    Returns:\n",
    "    -------\n",
    "    psi_values: np.array\n",
    "        Calculated Psi Values\n",
    "    time: Time_Object\n",
    "        Timestamp\n",
    "    \n",
    "    '''\n",
    "    with open (f\"{path}\\\\{file}\", \"r\") as file: # opens the file\n",
    "        for i, line in enumerate(file):\n",
    "            if line.find(pattern) != -1 and i >0: # finds the line in the file\n",
    "                timestamp=file.readline(i+1) # Timestamp is in the next line\n",
    "                break\n",
    "                \n",
    "    timestamp=np.asarray(re.findall(r'\\d+', timestamp)).astype(int)[1:4] #extracts the time from timestamp\n",
    "    time=Time_Object(timestamp[0], timestamp[1], timestamp[2]) # creates Time_Object\n",
    "    numbers=np.asarray(re.findall(r'\\d+', line)).astype(int) #extracts the numbers for PSI Calculation\n",
    "    step_size=(numbers[2]-numbers[1])/numbers[3] # calculates the stepsize of the scan\n",
    "    psi_values=-np.asarray(np.arange(numbers[1], numbers[2]+step_size, step_size))+90\n",
    "    return psi_values, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lattice_spacing(tth, wavelength, hkl):\n",
    "    '''\n",
    "    Calculates the lattice spacing following the formular:     \n",
    "    lattice_spacing = 1/2*wavelength/sin(tth/2)*np.sqrt(np.sum(hkl**2)\n",
    "    \n",
    "      Parameters:\n",
    "    -------\n",
    "    tth: np.array\n",
    "        Theta two Theta angles\n",
    "    wavelength: Float\n",
    "        Used wavelength of the experiment\n",
    "    hkl: np.array\n",
    "        [h,k,l] of the plane\n",
    "        \n",
    "    Returns:\n",
    "    -------\n",
    "    lattice_spacing: float\n",
    "        Calculated lattice spacing\n",
    "    '''\n",
    "    return  1/2*wavelength/sin(tth/2)*np.sqrt(np.sum(hkl**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_stress(peak_positions, psi_values, xray_constant, wave_length, hkl):\n",
    "    '''\n",
    "    Calculates the stress using the sin2PSI method\n",
    "    OLS using https://www.statsmodels.org/dev/examples/notebooks/generated/ols.html\n",
    "        \n",
    "    Parameters:\n",
    "    -------\n",
    "    peak_positions: np.array\n",
    "        Position of the peaks\n",
    "    psi_values: np.array\n",
    "        Corresponding PSI values\n",
    "    xray_constant: float\n",
    "        X-Ray Constant\n",
    "    wave_length: float\n",
    "        Used Wavelength\n",
    "    hkl: np.array\n",
    "        [h,k,l] of the plane\n",
    "        \n",
    "        \n",
    "    Returns:\n",
    "    -------\n",
    "    _ : dict\n",
    "        Dict including values for:\n",
    "            stress: np.array\n",
    "                calculated stress\n",
    "            stress_min: np.array\n",
    "                minimal stress calculated from confidence interval\n",
    "            stress_max: np.array\n",
    "                maximal stress calculated from confidence interval\n",
    "            k: float\n",
    "                sloap of the fitted line y=kx+d\n",
    "            d: float\n",
    "                intercept of the fitted line y=kx+d\n",
    "            lattice_spacings: float\n",
    "                calculated lattice spacings\n",
    "            psi_values: np.array\n",
    "                corresponding PSI Values     \n",
    "    '''\n",
    "    psi_values=np.radians(psi_values)\n",
    "    peak_positions=np.radians(peak_positions)\n",
    "    sin_psi=np.sin(psi_values)**2\n",
    "    \n",
    "    d=wave_length/(2*np.sin(peak_positions/2))\n",
    "    lattice_spacings =d*np.sqrt(np.sum(hkl**2))\n",
    "    \n",
    "    data = pd.DataFrame({'x': list(sin_psi), 'y': list(lattice_spacings)}) #breaking change with pandas\n",
    "\n",
    "    model = ols(\"y ~ x\", data).fit()\n",
    "    k, d = model.params[1], model.params[0]\n",
    "\n",
    "    #print(dir(model))\n",
    "    ## check for \n",
    "    prstd, iv_l, iv_u = wls_prediction_std(model)\n",
    "    \n",
    "    \n",
    "    conf_int = model.conf_int(alpha=0.1)\n",
    "    plt.plot(sin_psi, lattice_spacings, 'o')\n",
    "    plt.plot(sin_psi, k*sin_psi+d)\n",
    "    plt.plot(sin_psi, conf_int[0][1]*sin_psi+conf_int[0][0], '--', 'r')\n",
    "    plt.plot(sin_psi, conf_int[1][1]*sin_psi+conf_int[1][0], '--', 'r')\n",
    "    \n",
    "    plt.plot(sin_psi, iv_l, '-.', 'r')\n",
    "    plt.plot(sin_psi, iv_u, '-.', 'r')\n",
    "    print(prstd)\n",
    "    plt.xlabel(\"sin2Psi\")\n",
    "    plt.ylabel(\"lattice spacing\")\n",
    "    \n",
    "    plt.xlim((np.min(sin_psi), np.max(sin_psi)))\n",
    "    plt.ylim((np.min(lattice_spacings), np.max(lattice_spacings)))\n",
    "    plt.show()\n",
    "    stress=k/(xray_constant*10**(-5)*lattice_spacings[0])\n",
    "    stress_min = conf_int[0][1]/(xray_constant*10**(-5)*lattice_spacings[0])\n",
    "    stress_max = conf_int[1][1]/(xray_constant*10**(-5)*lattice_spacings[0])\n",
    "    \n",
    "    return {\"stress\":stress,\"stress_min\":stress_min, \"stress_max\":stress_max, \"k\":k, \"d\":d , \"lattice_spacing\":lattice_spacings, \"psi_values\":psi_values, 'sin2_psi':sin_psi}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_time(stress_data):\n",
    "    '''\n",
    "    Checks if time stamp changes from 24:00 to 00:00 and adds a day to still be bigger than other timestamp\n",
    "    \n",
    "    Parameters:\n",
    "    -------\n",
    "    stress_data: dict()\n",
    "                Dictionary must include key \"time\" inside single experimental datapoint\n",
    "                stress_data[\"experimental datapoint\"][\"key\"]: Time_Object\n",
    "                    Time_Object that needs to be checked\n",
    "        \n",
    "        \n",
    "    Returns:\n",
    "    -------\n",
    "     stress_data: dict()\n",
    "                Dictionary must include key \"time\" inside single experimental datapoint\n",
    "                stress_data[\"experimental datapoint\"][\"key\"]: Time_Object\n",
    "                    Time_Object that was checked\n",
    "    '''\n",
    "    next_day=False\n",
    "    keys=list(stress_data.keys()) # keys are the numbers of the stress measurements\n",
    "    \n",
    "    for i, key in enumerate(keys):\n",
    "        if next_day:\n",
    "            stress_data[key][\"time\"].add_day(1)\n",
    "        if i > 0:\n",
    "            print(stress_data[keys[i-1]][\"time\"].show_time())\n",
    "            if stress_data[keys[i-1]][\"time\"].hour == 24:\n",
    "                if stress_data[key][\"time\"].smaller_than(stress_data[keys[i-1]][\"time\"]):\n",
    "                    print(\"First Timestamp\")\n",
    "                    stress_data[key][\"time\"].show_time()\n",
    "                    print(\"Second Timestamp\")\n",
    "                    stress_data[keys[i-1]][\"time\"].show_time()\n",
    "                    next_day=True\n",
    "                \n",
    "    return stress_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_samples(path, dat_files, spec_file, pattern, xray_constant, wave_length, hkl, peak_parameters):\n",
    "    '''\n",
    "    Evaluates a single stress measurement and straining experiments from KMC-II Beamline of BESSY II. Correlates .dat and spec file.\n",
    "        \n",
    "    Parameters:\n",
    "    -------\n",
    "        path: String\n",
    "            Path to file\n",
    "        dat_files: String\n",
    "            Name of the .dat file including .dat suffix\n",
    "        spec_file: String\n",
    "           Name of the spec file\n",
    "        pattern:\n",
    "            Pattern where to find infomation in the spec_file\n",
    "        xray_constant: Float\n",
    "            X-Ray Constant\n",
    "        wave_length: Float\n",
    "            Wave Length of Experiment\n",
    "        hkl: np.array\n",
    "            [h,k,l] of the plane\n",
    "        peak_parameters: list/np.array\n",
    "            List of theta angles - Positions to fit\n",
    "            The Peak is automatically found between Start_Peak and End_Peak\n",
    "            Noise is calculated between Start_Noise - Start_Peak and End_Peak-End_Noise\n",
    "            [Start_Noise, Start_Peak, End_Peak, End_Noise]\n",
    "            \n",
    "    Returns:\n",
    "    -------\n",
    "        single_experiment: Dictonary\n",
    "                Dictonary of Single streee measurement with different calculated an measured values as keys. \n",
    "    '''\n",
    "    peak_positions=[]\n",
    "    all_fwhm=[]\n",
    "    for file in dat_files: # read and work all .dat files\n",
    "        tth, intens = read_dat_file(path, file)\n",
    "        print(file) # prints file_name to console\n",
    "        two_theta, max_intensity, nu, fwhm=fit_peak(tth, intens, peak_parameters[0], peak_parameters[1], peak_parameters[2], peak_parameters[3])\n",
    "        peak_positions.append(two_theta[0])\n",
    "        all_fwhm.append(fwhm[0])\n",
    "        \n",
    "        \n",
    "    peak_positions=np.asarray(peak_positions) \n",
    "    psi_values, time=extract_scan_data(path, spec_file, pattern)\n",
    "    \n",
    "    single_stress_measurement = calculate_stress(peak_positions, psi_values, xray_constant, wave_length, hkl) # evaluate single experiment for stress\n",
    "    single_stress_measurement[\"time\"] = time #add time_column to dict\n",
    "    single_stress_measurement[\"fwhm\"] = all_fwhm\n",
    "    return single_stress_measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_anton(path, file):\n",
    "    '''\n",
    "    Reads .xls Files extracted from Anton Paar Setup    \n",
    "    \n",
    "    Parameters:\n",
    "    -------\n",
    "        path: String\n",
    "            Path to file\n",
    "        file: String\n",
    "            Filename including the suffix .xls\n",
    "       \n",
    "            \n",
    "    Returns:\n",
    "    -------\n",
    "        anton: dataframe\n",
    "            Data extracted from xls. file, time allready checked for experiments running over midnight \n",
    "    '''\n",
    "    anton=pd.read_excel(f\"{path}\\\\{file}\", skiprows=7, names=[\"timestamp\", \"duration\", \"position\", \"displacement\", \"force\",\"rel_force\", \"elongation\", \"stress\"])   \n",
    "    next_day=False # for experiments changing from 24:00 to 00:00\n",
    "    \n",
    "    time=[]\n",
    "    for i, element in enumerate(anton.timestamp):\n",
    "        timestamp=list(re.findall(r'\\d+', str(element)))\n",
    "        if len(timestamp)<7:\n",
    "            timestamp.append(\"0\")\n",
    "        time.append(Time_Object(int(timestamp[3]), int(timestamp[4]), int(timestamp[5]), int(float(f\"0.{timestamp[6]}\")*60)))\n",
    "        if next_day:\n",
    "            time[i].add_day(1)\n",
    "        if i > 0: # wouldn't make sense for first element\n",
    "            if time[i-1] == 24:\n",
    "                if time[i].smaller_than(time[i-1]): # checks if day is over\n",
    "                    next_day=True\n",
    "    time=np.asarray(time)\n",
    "    anton[\"time\"]=time\n",
    "    return anton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlate_anton(stress_result, path_anton, file_anton):\n",
    "    '''\n",
    "    Correlates data of evaluated in-situ straining of KMC II at BESSY II to data collected by Anton Paar straining device.\n",
    "    Adds the corresponding strains to the evaluated values.\n",
    "    \n",
    "    Parameters:\n",
    "    -------\n",
    "        stress_reslut: Dictionary\n",
    "            Dictionary of the evaluated Experiment\n",
    "        path_anton: String\n",
    "            Path to Anton-Paar xls File\n",
    "        file_anton: String\n",
    "            Name of Anton-Paar file including .xls suffix\n",
    "       \n",
    "            \n",
    "    Returns:\n",
    "    -------\n",
    "        Correlation Plot.\n",
    "        \n",
    "        anton: dataframe\n",
    "            Anton Paar data\n",
    "        stress_result: Dicitionary\n",
    "            Evaluated experiments now also including respective elongation \n",
    "            can be called usings:\n",
    "                stress_result[\"stress_measurement\"][\"elongation\"]\n",
    "    '''\n",
    "    keys = stress_result.keys()\n",
    "    anton = read_anton(path_anton, file_anton)   \n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    j=0\n",
    "    for key in keys:\n",
    "        for i,element in enumerate(anton.time):\n",
    "            if i < j:\n",
    "                pass\n",
    "            if stress_result[key]['time'].greater_than(element):\n",
    "                pass\n",
    "            else:    \n",
    "                ax.plot(anton.elongation[i], stress_result[key][\"stress\"], 'o', c=\"r\")\n",
    "                plt.vlines(anton.elongation[i],stress_result[key][\"stress_min\"],stress_result[key][\"stress_max\"], color='black')\n",
    "                stress_result[key][\"elongation\"]=anton.elongation[i] # adding values to the stress_result dict\n",
    "                i=j\n",
    "                break\n",
    "    ax2 = ax.twinx()\n",
    "    ax2.plot(anton.elongation, anton.force)\n",
    "    ax2.set_ylabel(\"Force - Anton Paar\")\n",
    "    ax.set_ylabel(\"Stress - sin2psi\")\n",
    "    ax.set_xlabel(\"Elongation - Anton Paar\")\n",
    "    return anton, stress_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sample(path, spec_file, scan_start, scan_end, xray_constant, wavelength, peak, peak_params):\n",
    "    '''\n",
    "    Starts complete evaluation of in-situ straining experiment performed at KMC II at BESSY II.\n",
    "    \n",
    "    Parameters:\n",
    "    -------\n",
    "        path: String\n",
    "            Path to folder where dat and spec files are present\n",
    "        spec_file: String\n",
    "            Name of the Spec_file, no suffix needed\n",
    "        scan_start: int\n",
    "            First .dat file Number belonging to the experiment\n",
    "        scan_end: int\n",
    "            Last .dat file Number belonging to the experiment\n",
    "        xray_constant: float\n",
    "            X-Ray Constant\n",
    "        wavelength: float\n",
    "            Used wavelength during the experiment\n",
    "        peak: list\n",
    "            [h,k,l] of the peak\n",
    "        peak_params: list/np.array\n",
    "            List of theta angles - Positions to fit\n",
    "            The Peak is automatically found between Start_Peak and End_Peak\n",
    "            Noise is calculated between Start_Noise - Start_Peak and End_Peak-End_Noise\n",
    "            [Start_Noise, Start_Peak, End_Peak, End_Noise] \n",
    "       \n",
    "            \n",
    "    Returns:\n",
    "    -------\n",
    "        stress_result: Dictionary\n",
    "            \n",
    "    '''\n",
    "    os.chdir(path)\n",
    "    stress_result=dict()\n",
    "    for element in range(scan_start, scan_end+1):\n",
    "        if element < 10:\n",
    "            files = np.asarray(glob(f'*000{element}.*.dat'))\n",
    "        else:\n",
    "            files = np.asarray(glob(f'*00{element}.*.dat'))\n",
    "        stress_result[element] = evaluate_samples(path, files, spec_file, f\"#S {element}  ascan  chi\", xray_constant, wavelength, np.asarray(peak), peak_params)\n",
    "    \n",
    "    \n",
    "    keys=stress_result.keys()\n",
    "    for key in keys:\n",
    "        plt.plot(stress_result[key][\"sin2_psi\"], stress_result[key][\"lattice_spacing\"], \"-o\")\n",
    "    plt.xlabel(\"Sin2Psi\")\n",
    "    plt.ylabel(\"lattice spacing\")\n",
    "    plt.show()\n",
    "    \n",
    "    #stress_result=check_time(stress_result)\n",
    "    return stress_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(path, file_name, stress_result):\n",
    "    '''\n",
    "    Saves stress and elongation of anton paar\n",
    "    '''\n",
    "    keys = list(stress_result.keys())\n",
    "    stress = []\n",
    "    elongation = []\n",
    "    stress_max = []\n",
    "    stress_min =[]\n",
    "    for key in keys:\n",
    "        stress.append(stress_result[key][\"stress\"])\n",
    "        elongation.append(stress_result[key][\"elongation\"])\n",
    "        stress_max.append(stress_result[key][\"stress_max\"])\n",
    "        stress_min.append(stress_result[key][\"stress_min\"])\n",
    "    end_result=pd.DataFrame({'stress' : stress,'elongation' : elongation, \"stress_max\": stress_max, \"stress_min\": stress_min})\n",
    "    end_result.to_excel(f\"{path}//{file_name}_results.xlsx\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
